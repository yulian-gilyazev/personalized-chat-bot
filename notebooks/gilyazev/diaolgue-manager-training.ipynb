{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "2b9def44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_scheduler\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from util.dialogue_manager import  DialogueManagerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "47846b27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:4'\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "03abf7c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bavard/personachat_truecased\")\n",
    "persona_qualities = list(set([sent \n",
    "                      for item in dataset['train']['personality'] \n",
    "                          for sent in item]))\n",
    "persona_quality_to_id = {quality: i for i, quality in enumerate(persona_qualities)}\n",
    "print(f'{len(persona_qualities)} persona qualities')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3ae2c270",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "2b803776",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "    outputs = {\n",
    "        \"input_ids\": tokenizer(\"\\n-----\\n\".join(example[\"history\"]), padding='max_length', truncation=True)[\"input_ids\"]\n",
    "    }\n",
    "    outputs[\"labels\"] = outputs[\"input_ids\"]\n",
    "    return outputs\n",
    "\n",
    "def get_classes(example):\n",
    "    outputs = {\n",
    "        \"classes\": tuple(persona_quality_to_id[item] for item in example[\"personality\"] \n",
    "                          if item in persona_quality_to_id.keys())\n",
    "    }\n",
    "    return outputs\n",
    "\n",
    "tokenized_datasets = (\n",
    "    dataset\n",
    "        .map(get_classes, num_proc=6)\n",
    "        .map(tokenize, num_proc=6)\n",
    ")\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "43a3e43f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dialogue_manager = DialogueManagerModel(n_classes=len(persona_qualities), device=DEVICE, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aec0cd6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['personality', 'candidates', 'history', 'conv_id', 'utterance_idx', 'classes', 'input_ids', 'labels'],\n",
       "        num_rows: 131438\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['personality', 'candidates', 'history', 'conv_id', 'utterance_idx', 'classes', 'input_ids', 'labels'],\n",
       "        num_rows: 7801\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "609e80aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/jagiljazev/.cache/huggingface/datasets/bavard___personachat_truecased/full/1.0.0/73ee8f1a0d9e42255af5a8301877a2f3ac638e55b1cd9cbccca5ab7e23d2b638/cache-cd33c68f172c8d3f.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=SEED)\n",
    "val_dataset = tokenized_datasets[\"validation\"].shuffle(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ccb292e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "n_classes = len(persona_qualities)\n",
    "optimizer = torch.optim.Adam(dialogue_manager.model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9ba9a53e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xrhmnvs5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Ap@k</td><td>▁</td></tr><tr><td>Train Loss</td><td>▇█▇▇▇▇▇▆▇▇▆▇█▆▆▇▇▆▆▇▆▇▇▇▆▇▆▆▆▆▆█▇▅▆▄▅▃▂▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Ap@k</td><td>0.0</td></tr><tr><td>Train Loss</td><td>8.54361</td></tr><tr><td>Validation Loss</td><td>2.56849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">kind-blaze-1</strong>: <a href=\"https://wandb.ai/yulian-gilyazev/dialogue-manager-distilbert-best-uncased/runs/xrhmnvs5\" target=\"_blank\">https://wandb.ai/yulian-gilyazev/dialogue-manager-distilbert-best-uncased/runs/xrhmnvs5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221029_134827-xrhmnvs5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xrhmnvs5). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b8cae12a114dffbfdada551ac93955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666895578382537, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jagiljazev/personalized-chat-bot/notebooks/gilyazev/wandb/run-20221029_141051-th7kiv0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/yulian-gilyazev/dialogue-manager-model-distilbert-base-uncased/runs/th7kiv0b\" target=\"_blank\">major-cherry-1</a></strong> to <a href=\"https://wandb.ai/yulian-gilyazev/dialogue-manager-model-distilbert-base-uncased\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/yulian-gilyazev/dialogue-manager-model-distilbert-base-uncased/runs/th7kiv0b?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa3643189a0>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"dialogue-manager-model-distilbert-base-uncased\",\n",
    "    config={\n",
    "        \"batch_size\": batch_size, \n",
    "        \"lr\": lr, \n",
    "        \"optimizer\": 'adam', \n",
    "        'model_name': 'distilbert-base-uncased'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e96bc782",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def p_k(outputs, y_true, k=10):\n",
    "    true_num = len(y_true)\n",
    "    best_ind = np.argpartition(outputs, -k)[-k:]\n",
    "    precision = len(set(best_ind).intersection(set(y_true))) / true_num\n",
    "    return precision\n",
    "\n",
    "def ap_k(outputs, y_trues):\n",
    "    precisions = [p_k(output, y_true) for output, y_true in zip(outputs, y_trues)]\n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "29671dc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_freq = 50\n",
    "val_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "7868a28b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    loss = []\n",
    "    predictions = []\n",
    "    ys = []\n",
    "    batch_size = 64\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(val_size // batch_size)):\n",
    "            batch = val_dataset[i * batch_size: (i + 1) * batch_size]\n",
    "            X = torch.tensor(batch['input_ids']).to(DEVICE)\n",
    "            y = torch.zeros((X.shape[0], n_classes))\n",
    "            for i, col in enumerate(batch['classes']):\n",
    "                t = len(col)\n",
    "                for val in col:\n",
    "                    y[i, val] = 1 / t\n",
    "            y = y.to(DEVICE)\n",
    "            outputs = dialogue_manager(X)['logits']\n",
    "            loss.append(criterinon(outputs, y).detach().cpu().numpy())\n",
    "            predictions += [item.detach().cpu().numpy() for item in outputs]\n",
    "            ys += [item.detach().cpu().numpy() for item in y]\n",
    "    return ap_k(predictions, ys), np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019292f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bafc5c2f7a5403aa48864b05e000b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064bf4c6ea324240bca72e6a32a7c0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dc3314435d4ee7bcb905b42c816817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540f4cace36b440c8ae5ceee9d9dbfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c35669d8b4f4014b2e0e7a50094f082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2efb071e6e48f083d1215c32f6773e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for j in tqdm(range(len(train_dataset) // batch_size)):\n",
    "        batch = train_dataset[j * batch_size: (j + 1) * batch_size]\n",
    "        X = torch.tensor(batch['input_ids']).to(DEVICE)\n",
    "        y = torch.zeros((X.shape[0], n_classes))\n",
    "        for i, col in enumerate(batch['classes']):\n",
    "            t = len(col)\n",
    "            for val in col:\n",
    "                y[i, val] = 1 / t\n",
    "        y = y.to(DEVICE)\n",
    "        dialogue_manager.train()\n",
    "        outputs = dialogue_manager(X)['logits']\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        wandb.log({\"Train Loss\": loss.detach().cpu().numpy()})\n",
    "        if j % val_freq == 1:\n",
    "            ap_k_val, val_loss = validate(dialogue_manager)\n",
    "            wandb.log({\"Ap@k\": ap_k_val, 'Validation Loss': val_loss})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb212baf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}